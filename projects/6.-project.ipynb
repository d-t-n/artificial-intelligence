{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 6. Apply algorithms to train an image classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a real-life applied Python code example for training an image classifier using Vision Transformers (ViT) with transfer learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.models.vision_transformer import VisionTransformer\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set parameters\n",
    "num_classes = 10\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet normalization\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Load pre-trained ResNet-50 model\n",
    "resnet = resnet50(pretrained=True)\n",
    "resnet.fc = nn.Linear(2048, num_classes)  # Replace the fully connected layer\n",
    "\n",
    "# Freeze the layers of ResNet\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Create Vision Transformer (ViT) model\n",
    "vit = VisionTransformer(\n",
    "    img_size=224,\n",
    "    patch_size=16,\n",
    "    num_classes=num_classes,\n",
    "    dim=768,\n",
    "    depth=12,\n",
    "    heads=12,\n",
    "    mlp_dim=3072,\n",
    "    dropout=0.1,\n",
    "    emb_dropout=0.1\n",
    ")\n",
    "\n",
    "# Combine ResNet and ViT models\n",
    "model = nn.Sequential(resnet, vit)\n",
    "\n",
    "# Move the model to the device\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Move tensors to the device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print training progress\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{total_step}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code example, we leverage transfer learning by using a pre-trained ResNet-50 model as a feature extractor and combine it with a Vision Transformer (ViT) model for image classification. The code utilizes the CIFAR-10 dataset for demonstration purposes.\n",
    "\n",
    "First, the dataset is loaded and preprocessed using standard transformations. The ResNet-50 model is loaded and modified by replacing the fully connected layer to match the number of classes in the dataset. The ResNet layers are frozen to prevent their weights from being updated during training.\n",
    "\n",
    "The Vision Transformer (ViT) model is then created with specific parameters like image size, patch size, number of classes, depth, heads, etc. The ResNet and ViT models are combined into a single sequential model.\n",
    "\n",
    "Next, the model is moved to the available device (GPU if available). The loss function (CrossEntropyLoss) and optimizer (Adam) are defined.\n",
    "\n",
    "The training loop iterates through the dataset, performs forward and backward passes, and optimizes the model parameters. The progress is printed periodically to monitor the training process.\n",
    "\n",
    "After training, the model is evaluated on the test set. The accuracy is calculated by comparing the predicted labels with the ground truth labels.\n",
    "\n",
    "This code provides a starting point for training an image classifier using Vision Transformers with transfer learning. Additional modifications and optimizations can be made based on specific requirements and datasets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

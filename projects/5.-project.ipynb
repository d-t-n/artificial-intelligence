{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 5. Utilize sensors to execute perception tasks and their applications in intelligent systems\n",
    "## Project 5.1\n",
    "To provide a comprehensive real-life Python code example for utilizing sensors to execute perception tasks, I'll demonstrate a simple implementation using a camera sensor and OpenCV library for object detection. This code will detect objects in a live video stream from the camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load pre-trained model and configuration files\n",
    "net = cv2.dnn.readNetFromDarknet('yolov3.cfg', 'yolov3.weights')\n",
    "with open('coco.names', 'r') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Set up camera capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read frames from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Perform object detection\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1/255, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward()\n",
    "\n",
    "    # Process the detected objects\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                center_x = int(detection[0] * frame.shape[1])\n",
    "                center_y = int(detection[1] * frame.shape[0])\n",
    "                width = int(detection[2] * frame.shape[1])\n",
    "                height = int(detection[3] * frame.shape[0])\n",
    "                left = int(center_x - width / 2)\n",
    "                top = int(center_y - height / 2)\n",
    "                class_ids.append(class_id)\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append([left, top, width, height])\n",
    "\n",
    "    # Apply non-maximum suppression to remove redundant overlapping boxes\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "    # Draw bounding boxes and labels on the frame\n",
    "    for i in indices:\n",
    "        i = i[0]\n",
    "        box = boxes[i]\n",
    "        left, top, width, height = box\n",
    "        label = f'{classes[class_ids[i]]}: {confidences[i]:.2f}'\n",
    "        cv2.rectangle(frame, (left, top), (left + width, top + height), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Object Detection', frame)\n",
    "\n",
    "    # Exit loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code snippet, we utilize the camera sensor to capture a live video stream. The OpenCV library is used to perform object detection using the YOLOv3 model. The pre-trained model files (.cfg and .weights) need to be downloaded and provided. The coco.names file contains the names of the classes that the model can detect.\n",
    "\n",
    "The code sets up the camera capture and continuously reads frames from the camera. It then performs object detection on each frame using the YOLOv3 model. The detected objects are processed, and non-maximum suppression is applied to remove redundant bounding boxes. Finally, the code draws the bounding boxes and labels on the frame and displays it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
